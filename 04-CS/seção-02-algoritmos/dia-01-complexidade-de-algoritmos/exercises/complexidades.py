def squared_array(numbers):
    array_of_squares = []
    for number in numbers:
        array_of_squares.append(number * number)

    return array_of_squares

# Anota a√≠ üñä: Se falamos em ordem de complexidade 
# sem especificar se √© de tempo ou de mem√≥ria, assuma que √© de tempo!
# linear O(n) e constante O(1)

# Os arrays t√™m sempre o mesmo tamanho
def multiply_arrays(array1, array2):
    result = []
    for number1 in array1:
        for number2 in array2:
            result.append(number1 + number2)

    return result


def multiply_arrays(array1, array2):
    result = []
    number_of_iterations = 0

    for number1 in array1:
        print(f'Array 1: {number1}')
        for number2 in array2:
            print(f'Array 2: {number2}')
            result.append(number1 * number2)
            number_of_iterations += 1

    print(f'{number_of_iterations} itera√ß√µes!')
    return result


meu_array = [1, 2, 3, 4, 5]

multiply_arrays(meu_array, meu_array)

# Para o exemplo acima, no qual as duas entradas continham 5 elementos, 
# foram necess√°rias 25 opera√ß√µes para obtermos o resultado final!

# Anota a√≠ üñä: conforme aumentamos o tamanho dos arrays de entrada, 
# o n√∫mero de opera√ß√µes para a execu√ß√£o do algoritmo cresce ao quadrado. 
# Isso significa que, para entradas de tamanho n, a quantidade de 
# opera√ß√µes para executar o algoritmo √© de n¬≤. Sendo assim, a 
# complexidade desse algoritmo √© dada por O(n¬≤) e a chamamos de 
# Complexidade Quadr√°tica.

# A Ordem de Complexidade diz respeito √† taxa de crescimento do tempo de execu√ß√£o (ou espa√ßo de mem√≥ria ocupado) de um algoritmo, na medida em que aumentamos o tamanho da sua entrada;

# Uma complexidade √© O(1) (constante), quando o tempo de execu√ß√£o do algoritmo independe do tamanho da entrada;

# Uma complexidade √© O(n) (linear) quando a taxa de crescimento em seu tempo de execu√ß√£o √© linear: se aumentamos a entrada em 2 vezes, aumentamos o tempo de execu√ß√£o em 2 vezes;

# Uma complexidade √© O(n¬≤) (quadr√°tica) quando a taxa de crescimento do tempo de execu√ß√£o do algoritmo √© quadr√°tica: se aumentamos a entrada em 2 vezes, aumentamos o tempo de execu√ß√£o em 4 (ou 2¬≤) vezes;

# Uma complexidade √© O(n¬≥) (c√∫bica) quando a taxa de crescimento do tempo de execu√ß√£o do algoritmo √© c√∫bica: se aumentamos a entrada em 2 vezes, aumentamos o tempo de execu√ß√£o em 8 (2¬≥) vezes.


# complexidade logaritmica O(log n)
# Suponha que temos um algoritmo cuja entrada n √© igual a 4, se tivermos um algoritmo O(log n) a ser executado com essa entrada, teremos que fazer apenas 2 opera√ß√µes para execut√°-lo, pois log‚ÇÇn (l√™-se: ‚Äúlog de n na base 2‚Äù) √© igual a 2. Se a nossa entrada fosse o dobro, ou seja, 8 ter√≠amos que realizar apenas 3 opera√ß√µes para chegar ao fim da execu√ß√£o. Ao dobrar o valor da entrada novamente, com n igual a 16, ter√≠amos que realizar apenas 4 opera√ß√µes (log‚ÇÇn √© igual a 4) e assim sucessivamente.

# Anota a√≠ üñä: O n√∫mero de opera√ß√µes para executar o algoritmo logar√≠tmico tem uma rela√ß√£o inversa ao tamanho da entrada: quanto maior ela √©, menor o n√∫mero de opera√ß√µes e, consequentemente, menor o tempo para a execu√ß√£o do algoritmo!

# A estrutura deve estar ordenada para que a busca bin√°ria funcione
def binary_search(numbers, target):
    # definir os √≠ndices
    start = 0
    end = len(numbers) - 1

    while start <= end: # os √≠ndices podem ser no m√°ximo iguais, o in√≠cio n√£o pode ultrapassar o fim
        mid = (start + end) // 2 # encontro o meio

        if numbers[mid] == target: # se o elemento do meio for o alvo, devolve a posi√ß√£o do meio
            return mid
        
        if target < numbers[mid]: # se o elemento for menor, atualiza o √≠ndice do fim
            end = mid - 1
        else: # caso contr√°rio, atualiza o √≠ndice do inicio
            start = mid + 1
    
    return -1 # N√£o encontrou? Retorna -1

numbers = [2, 3, 4, 10, 40]
target = 40

result = binary_search(numbers, target)
print(f"Elemento encontrado na posi√ß√£o: {result}")


# Essas complexidades caracterizam algoritmos que, para aumentos pequenos no tamanho da entrada, aumentam enormemente o n√∫mero de opera√ß√µes a serem realizadas para serem executados e, consequentemente, seu tempo de execu√ß√£o. A rela√ß√£o do tempo de execu√ß√£o/espa√ßo ocupado em cada caso √© a seguinte:

# Exponencial: 2‚Åø (O(2‚Åø));
# Fatorial: n! (O(n!)).

# No caso de um algoritmo com Ordem de Complexidade Exponencial, para uma entrada de dados n que possui vinte elementos, o algoritmo realizar√° aproximadamente um milh√£o (ou 2¬≤‚Å∞) de opera√ß√µes. Para o caso fatorial, os mesmos vinte elementos rendem 24 quatrilh√µes de opera√ß√µes! (O n√∫mero exato √©: 2432902008176640000 opera√ß√µes üò®).

